

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Streaming ML Classification with Active Learning Model &mdash; spark-streaming-playground 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Spark Streaming Playground API" href="../api.html" />
    <link rel="prev" title="Stackoverflow Exploration" href="5_static_table_stackoverflow.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> spark-streaming-playground
          

          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../setup/setup.html">Spark Streaming Playground Environment Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Learning Materials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../host_urls_n_ports.html">Localhost Port Number used</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how_to_run.html">How to Run?</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="usecases.html">Usecases</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="1_dump_tweets.html">Dump Tweet data into Data Lake</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_trending_tweets.html">Trending Twitter Hash Tags</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_scalable_rest_api.html">Scalable REST end point a naive approach</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_spark_ml.html">Spark ML Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_static_table_stackoverflow.html">Stackoverflow Exploration</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Streaming ML Classification with Active Learning Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#implementation">Implementation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dataset">Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#labeling">Labeling</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#how-to-run">How to run?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api.html">Spark Streaming Playground API</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">spark-streaming-playground</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="usecases.html">Usecases</a> &raquo;</li>
        
      <li>Streaming ML Classification with Active Learning Model</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/usecases/6_full_ml_model_cycle.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="streaming-ml-classification-with-active-learning-model">
<h1>Streaming ML Classification with Active Learning Model<a class="headerlink" href="#streaming-ml-classification-with-active-learning-model" title="Permalink to this headline">¶</a></h1>
<p>A must read <a class="reference external" href="https://towardsdatascience.com/architecting-a-machine-learning-pipeline-a847f094d1c7">theory on Architecting a Machine Learning Pipeline</a></p>
<ul class="simple">
<li><p>In this use case we are gonna build ground up dataset from scratch from live streaming data.</p></li>
<li><p>Use programmatic methods to tag dataset, create golden dataset for ML training,
in an iterative manner till we are satisfied with model performance.</p></li>
<li><p>Build model and evaluate it on golden dataset</p></li>
<li><p>Deploy the model, classify the text</p></li>
<li><p>Extract the web links from tweets and store the urls</p></li>
</ul>
<div class="section" id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h2>
<p><img alt="../_images/ml_pipeline.png" src="../_images/ml_pipeline.png" /></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">1.</span> <span class="n">Data</span> <span class="n">Collection</span><span class="p">:</span>
    <span class="n">Tweets</span> <span class="o">-&gt;</span> <span class="n">Twitter</span> <span class="n">Stream</span> <span class="o">-&gt;</span> <span class="n">Tweepy</span> <span class="o">-&gt;</span> <span class="n">Kafka</span> <span class="n">Producer</span> <span class="o">-&gt;</span> <span class="n">Kafka</span> <span class="n">Stream</span>  <span class="o">-&gt;</span> <span class="n">Spark</span> <span class="n">Structured</span> <span class="n">Streaming</span> <span class="n">Consumer</span> <span class="o">-&gt;</span> <span class="n">Postgresql</span> <span class="k">as</span> <span class="n">one</span> <span class="n">single</span> <span class="n">raw</span> <span class="n">data</span> <span class="n">table</span>

<span class="mf">2.</span> <span class="n">Data</span> <span class="n">Labelling</span> <span class="ow">and</span> <span class="n">Splittling</span> 
   <span class="n">Posgresql</span> <span class="o">-&gt;</span> <span class="n">Raw</span> <span class="n">Dataset</span> <span class="n">Table</span> <span class="o">-&gt;</span> <span class="n">Split</span> <span class="o">-&gt;</span> <span class="n">Train</span><span class="o">/</span><span class="n">Test</span><span class="o">/</span><span class="n">Dev</span><span class="o">/</span><span class="n">Snorkel</span> <span class="n">dataset</span> <span class="n">tables</span> <span class="o">-&gt;</span> <span class="n">SSPLabeler</span><span class="p">(</span><span class="n">Snorkel</span> <span class="n">Labeler</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Labelled</span> <span class="n">Train</span><span class="o">/</span><span class="n">Test</span><span class="o">/</span><span class="n">Dev</span> <span class="n">dataset</span> <span class="n">on</span> <span class="n">Postgresql</span>
   <span class="n">Labelled</span> <span class="n">Train</span><span class="o">/</span><span class="n">Test</span><span class="o">/</span><span class="n">Dev</span> <span class="n">dataset</span> <span class="n">on</span> <span class="n">Posgresql</span><span class="o">-&gt;</span> <span class="n">Mannual</span> <span class="n">UI</span> <span class="n">Tagger</span> <span class="o">-&gt;</span>  <span class="n">Train</span><span class="o">/</span><span class="n">Test</span><span class="o">/</span><span class="n">Dev</span> <span class="n">dataset</span> <span class="k">with</span> <span class="n">golden</span> <span class="n">label</span> <span class="n">column</span> <span class="n">on</span> <span class="n">Posgresql</span>

<span class="mf">3.</span> <span class="n">Model</span> <span class="n">Training</span>
   <span class="n">Labelled</span> <span class="n">Train</span><span class="o">/</span><span class="n">Test</span><span class="o">/</span><span class="n">Dev</span> <span class="n">dataset</span> <span class="o">-&gt;</span> <span class="n">DL</span> <span class="n">Model</span> <span class="o">-&gt;</span> <span class="n">Model</span> <span class="n">Store</span>

<span class="mf">4.</span> <span class="n">Prediction</span> <span class="n">on</span> <span class="n">Live</span> <span class="n">Stream</span>
   <span class="n">Model</span> <span class="n">Store</span> <span class="o">-&gt;</span> <span class="n">Tensorflow</span> <span class="n">Serving</span> <span class="o">-&gt;</span> <span class="n">TF</span> <span class="n">API</span> <span class="n">End</span> <span class="n">Point</span>
   <span class="n">Tweets</span> <span class="o">-&gt;</span> <span class="n">Twitter</span> <span class="n">Stream</span> <span class="o">-&gt;</span> <span class="n">Tweepy</span> <span class="o">-&gt;</span> <span class="n">Kafka</span> <span class="n">Producer</span> <span class="o">-&gt;</span> <span class="n">Kafka</span> <span class="n">Stream</span>  <span class="o">-&gt;</span> <span class="n">Spark</span> <span class="n">Structured</span> <span class="n">Streaming</span> <span class="n">Consumer</span> <span class="o">-&gt;</span> <span class="n">UDF</span><span class="p">(</span><span class="n">TF</span> <span class="n">API</span> <span class="n">End</span> <span class="n">Point</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Filtered</span> <span class="n">AI</span> <span class="n">Tweets</span> <span class="o">-&gt;</span> <span class="n">Postgresql</span>

<span class="mf">5.</span> <span class="n">Dashboard</span>
   <span class="n">Postgresql</span> <span class="o">-&gt;</span> <span class="n">Flask</span> <span class="n">API</span> <span class="o">-&gt;</span> <span class="n">Dashboard</span>
</pre></div>
</div>
<div class="section" id="dataset">
<h3>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h3>
<p>We are interested to collect tweets that talks about Artificial Intelligence / Data Science in general.</p>
<p>Dataset creation involves:</p>
<ul class="simple">
<li><p>Observer the Tweets</p></li>
<li><p>Sample relevant tweets, with possible false positive data (i.r irrelevant tweets)</p></li>
<li><p>Dataset of format <code class="docutils literal notranslate"><span class="pre">parquet</span></code> with text column and label column. (parquet nicely packs special characters without the headache os parsing the CSV files)</p></li>
<li><p>Data splits</p></li>
</ul>
<p>creates dataset &#64; <a class="reference external" href="https://github.com/gyan42/spark-streaming-playground/tree/master/data/dataset/ssp/original">data/dataset/ssp/original</a></p>
<table border="1" class="docutils">
<thead>
<tr>
<th>File Name</th>
<th>Records</th>
<th>Info</th>
<th>Columns</th>
</tr>
</thead>
<tbody>
<tr>
<td>ssp_tweet_dataset.parquet</td>
<td>30K+</td>
<td>Full Raw Dataset</td>
<td>['created_at', 'text', 'source', 'expanded_url', 'media_url_https']</td>
</tr>
<tr>
<td>ssp_train_dataset.parquet</td>
<td>27K+</td>
<td>Train Data</td>
<td>['created_at', 'text', 'source', 'expanded_url', 'media_url_https']</td>
</tr>
<tr>
<td>ssp_LF_dataset.parquet</td>
<td>1000</td>
<td>Snorkell Dataset</td>
<td>["id", "text"]</td>
</tr>
<tr>
<td>ssp_test_dataset.parquet</td>
<td>1000</td>
<td>Test Data</td>
<td>["id", "text"]</td>
</tr>
<tr>
<td>ssp_val_dataset.parquet</td>
<td>500</td>
<td>Validation Data</td>
<td>["id", "text"]</td>
</tr>
</tbody>
</table></div>
<div class="section" id="labeling">
<h3>Labeling<a class="headerlink" href="#labeling" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><strong>Tagger</strong></p>
<ul class="simple">
<li><p>Mannual annotation plays a major role in ML pipeline, where humans needs to infuse domain information in to ML model.</p></li>
<li><p>Though there are more advanced tools like <a class="reference external" href="https://prodi.gy/">https://prodi.gy/</a>, I wanted to keep things tiddy and simple,
so a web tool has been put in place to get a hands on experience in tagging with respect to text classification.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">bin/tagger.sh</span></code></p>
<p>In this tool, you can:
- Upload multiple CSV/Parquet(preffered) data files with columns [id, text] and corresponding
CSV lable files with columns [lable, index]
- Tag each of the data files independently
- Download the files (as matter of fact the files lives in your home folder ;) )</p>
<p>Main screen…
<img alt="../_images/text_tagger1.png" src="../_images/text_tagger1.png" /></p>
<p>Upload CSV data…
<img alt="../_images/text_tagger_upload_csv.png" src="../_images/text_tagger_upload_csv.png" /></p>
<p>Upload Labels file…
<img alt="../_images/text_tagger_labels.png" src="../_images/text_tagger_labels.png" /></p>
<p>Main Tagger Screen…
<img alt="../_images/text_tagger_screen.png" src="../_images/text_tagger_screen.png" /></p>
</li>
<li><p><strong><a class="reference external" href="https://www.snorkel.org/">Snorkel</a></strong>
A semi automated way of preparing the dataset at scale for later use.</p></li>
</ul>
</div>
</div>
<div class="section" id="how-to-run">
<h2>How to run?<a class="headerlink" href="#how-to-run" title="Permalink to this headline">¶</a></h2>
<p>There are two ways of running, that is on docker or on your local machine. In either case, opening the terminal
is the difference, once the terminal is launched, the steps are common.</p>
<p>To get a new terminal for our docker instance run : <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">exec</span> <span class="pre">-it</span> <span class="pre">$(docker</span> <span class="pre">ps</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">sparkstructuredstreaming-pg</span> <span class="pre">|</span> <span class="pre">cut</span> <span class="pre">-d'</span> <span class="pre">'</span> <span class="pre">-f1)</span> <span class="pre">bash</span></code>
Note: We pull our container run id with <code class="docutils literal notranslate"><span class="pre">$(docker</span> <span class="pre">ps</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">sparkstructuredstreaming-pg</span> <span class="pre">|</span> <span class="pre">cut</span> <span class="pre">-d'</span> <span class="pre">'</span> <span class="pre">-f1)</span></code></p>
<p>This example needs three terminals:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cd /path/to/spark-streaming-playground/ # Local machine
cd /host  # On Docker &#39;spark-streaming-playground&#39; is mountes as a volume at /host/

#[producer] Guake terminal name! 
    bin/data/start_kafka_producer.sh

#[dump data]
    #by default 50K tweets (25K AI tweets + 25K False positive) will be collected and dumbed into the table
    bin/data/dump_raw_data_into_postgresql.sh
    
    python src/ssp/posgress/dataset_base.py --mode=upload

#[ssp data]
    #Reads the table as pandas dataframe, applies naive labelling, prepares the dataset needed for Text classifier and snorkel labelling
    bin/data/prepare_ssp_dataset.sh

#[snorkell] # TODO
    bin/models/run_snorkel_labeeler.sh

#[tagger]
    bin/flask/tagger.sh

#[DL Text classification Model]
    bin/models/build_naive_dl_text_classifier.sh 

#[Tensorflow Serving]
    export MODEL_DIR=/home/mageswarand/ssp/model/raw_tweet_dataset_2/naive_text_classifier/exported/
    # test the model 
    saved_model_cli show --dir ${MODEL_DIR}/1/ --all
    # start the serving server
    tensorflow_model_server \
      --rest_api_port=8501 \
      --model_name=&quot;naive_text_clf&quot; \
      --model_base_path=&quot;${MODEL_DIR}&quot;

# [Spark Streaming]
    bin/nlp/spark_dl_text_classification_main.sh
</pre></div>
</div>
<div class="section" id="references">
<h3>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65</p></li>
<li><p>https://towardsdatascience.com/how-to-build-a-complex-reporting-dashboard-using-dash-and-plotl-4f4257c18a7f</p></li>
<li><p>https://github.com/ucg8j/awesome-dash</p></li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../api.html" class="btn btn-neutral float-right" title="Spark Streaming Playground API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="5_static_table_stackoverflow.html" class="btn btn-neutral float-left" title="Stackoverflow Exploration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Mageswaran Dhandapani

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>