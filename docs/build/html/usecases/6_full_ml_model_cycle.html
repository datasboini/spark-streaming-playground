

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Streaming ML Classification with Active Learning Model &mdash; spark-streaming-playground 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ssp" href="../ssp/ssp.html" />
    <link rel="prev" title="Stackoverflow Exploration" href="5_static_table_stackoverflow.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> spark-streaming-playground
          

          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../setup/setup.html">Spark Streaming Playground Environment Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Learning Materials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../host_urls_n_ports.html">Localhost Port Number used</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how_to_run.html">How to Run?</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="usecases.html">Usecases</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="1_dump_tweets.html">Dump Tweet data into Data Lake</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_trending_tweets.html">Trending Twitter Hash Tags</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_scalable_rest_api.html">Scalable REST end point a naive approach</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_spark_ml.html">Spark ML Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_static_table_stackoverflow.html">Stackoverflow Exploration</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Streaming ML Classification with Active Learning Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#requirements">Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implementation">Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuration">Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#how-to-run">How to run?</a></li>
<li class="toctree-l3"><a class="reference internal" href="#take-aways-learning-s">Take Aways / Learning’s</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ssp/ssp.html">ssp</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">spark-streaming-playground</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="usecases.html">Usecases</a> &raquo;</li>
        
      <li>Streaming ML Classification with Active Learning Model</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/usecases/6_full_ml_model_cycle.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="streaming-ml-classification-with-active-learning-model">
<h1>Streaming ML Classification with Active Learning Model<a class="headerlink" href="#streaming-ml-classification-with-active-learning-model" title="Permalink to this headline">¶</a></h1>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Refer the following link for general architecture of our continuous integration ML pipeline<a class="reference external" href="https://towardsdatascience.com/architecting-a-machine-learning-pipeline-a847f094d1c7">theory on Architecting a Machine Learning Pipeline</a></p></li>
<li><p>Create a pipeline with following diagram as reference…<br /><img alt="../_images/ml_pipeline.png" src="../_images/ml_pipeline.png" /></p></li>
<li><p>Build ground up dataset for tweet classification (AI tweet or not) using the live streaming data</p></li>
<li><p>Dump the raw tweet data into a table in Postgresql DB called <code class="docutils literal notranslate"><span class="pre">streamingdb</span></code></p></li>
<li><p>Have configuration to prefix the name of the raw tweet data and version config to dump the tables into DB</p></li>
<li><p>Use semi supervised methods to tag dataset, for example frameworks like [https://www.snorkel.org/](https://www.snorkel.org/</p></li>
<li><p>Build a UI tool to annotate the semi supervised tagged data to create golden dataset for ML training</p></li>
<li><p>Build a Naive Deep Learning/ Neural network model and evaluate it on golden/sem supervised dataset</p></li>
<li><p>Deploy the model, classify the text</p></li>
<li><p>Extract the web links from tweets and store the urls</p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h2>
<ol>
<li><p>Problem Definition</p>
<ul class="simple">
<li><p>Build a modular streaming ML/DL pipeline</p></li>
</ul>
</li>
<li><p>Data Ingestion / Data Collection:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Tweets</span> <span class="o">---&gt;</span> <span class="n">Twitter</span> <span class="n">Stream</span> <span class="o">---&gt;</span> <span class="n">Tweepy</span> <span class="o">---&gt;</span> <span class="n">Kafka</span> <span class="n">Producer</span> <span class="o">---&gt;</span> <span class="n">Kafka</span> <span class="n">Stream</span> <span class="o">--</span>
               <span class="o">-&gt;</span> <span class="n">Spark</span> <span class="n">Structured</span> <span class="n">Streaming</span> <span class="n">Consumer</span> <span class="o">---&gt;</span> <span class="n">Postgresql</span> <span class="k">as</span> <span class="n">one</span> <span class="n">single</span> <span class="n">raw</span> <span class="n">data</span> <span class="n">table</span>
</pre></div>
</div>
</li>
<li><p>Data Preparation / Data Labelling and Segregation</p>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span>Posgresql ---&gt; Raw Dataset Table ---&gt; Split ---&gt; Train/Test/Dev/Snorkel dataset tables --
                  -&gt; SSPLabeler(Snorkel Labeler) ---&gt; Labelled Train/Test/Dev dataset stored in Postgresql &amp; Disk
Labelled Train/Test/Dev dataset on Posgresql---&gt; Mannual UI Tagger ---&gt;  Train/Test/Dev dataset with golden label column on Posgresql
</pre></div>
</div>
</li>
<li><p>Model Training and Evaluation</p>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span>Labelled Train/Test/Dev dataset ---&gt; DL Model ---&gt; Model Store
</pre></div>
</div>
</li>
<li><p>Deployment / Prediction on Live Stream</p>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span>Model Store ---&gt; Tensorflow Serving ---&gt; TF API End Point
Tweets ---&gt; Twitter Stream ---&gt; Tweepy ---&gt; Kafka Producer ---&gt; Kafka Stream  --
              -&gt; Spark Structured Streaming Consumer ---&gt; UDF(TF API End Point) --
                    -&gt; Filtered AI Tweets ---&gt; Postgresql
</pre></div>
</div>
</li>
<li><p>Monitoring / Dashboard</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Postgresql</span> <span class="o">---&gt;</span> <span class="n">Flask</span> <span class="n">API</span> <span class="o">---&gt;</span> <span class="n">Dashboard</span>
</pre></div>
</div>
</li>
</ol>
<p>Dataset tables:</p>
<ul class="simple">
<li><p>Tables are suffixed with <code class="docutils literal notranslate"><span class="pre">run/version</span> <span class="pre">id</span></code> starting from <code class="docutils literal notranslate"><span class="pre">0</span></code>, refer respective bin/*.sh files for version configurations</p></li>
</ul>
<table border="1" class="docutils">
<thead>
<tr>
<th>Table Name</th>
<th>Records</th>
<th>Info</th>
</tr>
</thead>
<tbody>
<tr>
<td>raw_tweet_dataset_0</td>
<td>50K+</td>
<td>Full Raw Dataset</td>
</tr>
<tr>
<td>deduplicated_raw_tweet_dataset_0</td>
<td>~</td>
<td>Depulicated on text column</td>
</tr>
<tr>
<td>test_dataset_0</td>
<td>1000</td>
<td>Test dataset</td>
</tr>
<tr>
<td>dev_dataset_0</td>
<td>500</td>
<td>Dev dataset</td>
</tr>
<tr>
<td>snorkel_train_dataset_0</td>
<td>10K</td>
<td>Snorkel train dataset</td>
</tr>
<tr>
<td>train_dataset_0</td>
<td>~</td>
<td>Model train dataset</td>
</tr>
</tbody>
</table><p><img alt="../_images/6_full_ml_model_cycle.png" src="../_images/6_full_ml_model_cycle.png" /></p>
</div>
<hr class="docutils" />
<div class="section" id="configuration">
<h2>Configuration<a class="headerlink" href="#configuration" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://gyan42.github.io/spark-streaming-playground/build/html/ssp/ssp.utils.html#ssp.utils.ai_key_words.AIKeyWords">Tweets Keywords Used</a></p></li>
<li><p>Config file used : <a class="reference external" href="https://github.com/gyan42/spark-streaming-playground/blob/756ee7c204039c8a3bc890a95e1da78ac2d6a9ee/config/default_ssp_config.gin">default_ssp_config.gin</a></p></li>
<li><p><a class="reference external" href="https://gyan42.github.io/spark-streaming-playground/build/html/ssp/ssp.kafka.producer.html">TwitterProducer</a></p></li>
<li><p><a class="reference external" href="https://gyan42.github.io/spark-streaming-playground/build/html/ssp/ssp.spark.streaming.consumer.html?highlight=twitterdataset#ssp.spark.streaming.consumer.twiteer_stream_consumer.TwitterDataset">TwitterDataset</a></p></li>
<li><p><a class="reference external" href="https://gyan42.github.io/spark-streaming-playground/build/html/ssp/ssp.ml.dataset.html?highlight=sspmldataset#ssp.ml.dataset.prepare_dataset.SSPMLDataset">SSPMLDataset</a></p></li>
<li><p><a class="reference external" href="https://github.com/gyan42/spark-streaming-playground/blob/756ee7c204039c8a3bc890a95e1da78ac2d6a9ee/config/tagger.gin">tagger.gin</a></p></li>
<li><p><a class="reference external" href="https://gyan42.github.io/spark-streaming-playground/build/html/ssp/ssp.dl.tf.classifier.html?highlight=naivetextclassifier#ssp.dl.tf.classifier.naive_text_classifier.NaiveTextClassifier">NaiveTextClassifier</a></p></li>
<li></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="how-to-run">
<h2>How to run?<a class="headerlink" href="#how-to-run" title="Permalink to this headline">¶</a></h2>
<p>There are two ways of running, that is on docker or on your local machine. In either case, opening the terminal
is the difference, once the terminal is launched, the steps are common.</p>
<p>To get a new terminal for our docker instance run : <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">exec</span> <span class="pre">-it</span> <span class="pre">$(docker</span> <span class="pre">ps</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">sparkstructuredstreaming-pg</span> <span class="pre">|</span> <span class="pre">cut</span> <span class="pre">-d'</span> <span class="pre">'</span> <span class="pre">-f1)</span> <span class="pre">bash</span></code>
Note: We pull our container run id with <code class="docutils literal notranslate"><span class="pre">$(docker</span> <span class="pre">ps</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">sparkstructuredstreaming-pg</span> <span class="pre">|</span> <span class="pre">cut</span> <span class="pre">-d'</span> <span class="pre">'</span> <span class="pre">-f1)</span></code></p>
<p>This example needs multiple terminals:</p>
<ul>
<li><p>On each terminal move to the source root folder:</p>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span># Local machine
cd /path/to/spark-streaming-playground/ 

# On Docker &#39;spark-streaming-playground&#39; is mountes as a volume at /host/
cd /host  

export PYTHONPATH=$(pwd)/src/:$PYTHONPATH
</pre></div>
</div>
</li>
<li><p>Data collection</p>
<ul class="simple">
<li><p>There can be of two ways</p></li>
<li><p>First way is dumping data from live stream, which may take few hours depending up on the
frequency of the AI/ML/Big Data tweets</p></li>
</ul>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span>#[producer] Guake terminal name! 
    vim bin/data/start_kafka_producer.sh
    bin/data/start_kafka_producer.sh

#[dump data]
    #by default 50K tweets (25K AI tweets + 25K False positive) will be collected and dumbed into the table
    vim bin/data/dump_raw_data_into_postgresql.sh
    bin/data/dump_raw_data_into_postgresql.sh
</pre></div>
</div>
<ul class="simple">
<li><p>Second way is use the dump as part of this repo</p></li>
</ul>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span>python src/ssp/posgress/dataset_base.py --mode=upload

# If there is any Postgresql permission error related to schema, run below command on `psql` terminal
GRANT ALL ON schema public TO sparkstreaming;
</pre></div>
</div>
</li>
<li><p>Data preparation for model training, with default snorkel labeller</p>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span>#[ssp data]
    vim bin/data/prepare_ssp_dataset.sh # check the version points to the one we wanted, to begin with it has to be 0
    vim config/default_ssp_config.gin # check for `SSPMLDataset` params
    bin/data/prepare_ssp_dataset.sh
</pre></div>
</div>
<p>Snorkell Label Function coverage will be printed as part of the logs, as follows:</p>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span>                        j Polarity  Coverage  Overlaps  Conflicts
  is_ai_tweet         0      [1]    0.3125    0.0587     0.0587
  is_not_ai_tweet     1      [0]    0.3469    0.1597     0.0000
  not_data_science    2      [0]    0.1084    0.0983     0.0482
  not_neural_network  3      [0]    0.0036    0.0030     0.0030
  not_big_data        4      [0]    0.1133    0.1048     0.0057
  not_nlp             5      [0]    0.0132    0.0120     0.0004
  not_ai              6      [0]    0.0084    0.0067     0.0059
  not_cv              7      [0]    0.0081    0.0068     0.0016
</pre></div>
</div>
</li>
<li><p>Mannual tagger
<img alt="../_images/text_tagger.png" src="../_images/text_tagger.png" /></p>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span>#[tagger]
    bin/flask/tagger.sh
</pre></div>
</div>
</li>
<li><p>Evalaute the Snorkel labeller with respect to hand labels</p>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span>#[snorkell]
    bin/models/evalaute_snorkel_labeller.sh
</pre></div>
</div>
</li>
<li><p>Train Deep Learning model</p>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span>#[DL Text classification Model]
    bin/models/build_naive_dl_text_classifier.sh 
</pre></div>
</div>
</li>
<li><p>Start Tensorflow Serving</p>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span>#[Tensorflow Serving]
    export MODEL_DIR=/home/mageswarand/ssp/model/raw_tweet_dataset_2/naive_text_classifier/exported/
    # test the model 
    saved_model_cli show --dir ${MODEL_DIR}/1/ --all
    # start the serving server
    tensorflow_model_server \
      --rest_api_port=8501 \
      --model_name=&quot;naive_text_clf&quot; \
      --model_base_path=&quot;${MODEL_DIR}&quot;
</pre></div>
</div>
</li>
<li><p>Start live Spark streaming for AI/Data Science tweet classification</p>
<div class="highlight-shell script notranslate"><div class="highlight"><pre><span></span># [Spark Streaming]
    bin/nlp/spark_dl_text_classification_main.sh
</pre></div>
</div>
</li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="take-aways-learning-s">
<h2>Take Aways / Learning’s<a class="headerlink" href="#take-aways-learning-s" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>TODOs</p></li>
</ul>
<hr class="docutils" />
<p><strong>References</strong></p>
<ul class="simple">
<li><p>https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65</p></li>
<li><p>https://towardsdatascience.com/how-to-build-a-complex-reporting-dashboard-using-dash-and-plotl-4f4257c18a7f</p></li>
<li><p>https://github.com/ucg8j/awesome-dash</p></li>
<li><p>https://github.com/tensorflow/serving</p></li>
<li><p>https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/serving_kubernetes.md TODO</p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../ssp/ssp.html" class="btn btn-neutral float-right" title="ssp" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="5_static_table_stackoverflow.html" class="btn btn-neutral float-left" title="Stackoverflow Exploration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Mageswaran Dhandapani

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>